{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file: '/home/masterartem/Studies/UdacitySelfDriving/BehavioralCloning/sample_data/IMG/center_2020_02_16_16_22_49_042.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fd4bf4982f87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_img\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'center_2020_02_16_16_22_49_042.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_img\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'center_2020_02_16_16_22_49_042.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;31m# Get reader and read first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mget_reader\u001b[0;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;31m# Create request object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m# Get format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, uri, mode, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# Parse what was given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;31m# Set extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m_parse_uri\u001b[0;34m(self, uri)\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;31m# Reading: check that the file exists (but is allowed a dir)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such file: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m                 \u001b[0;31m# Writing: check that the directory to write to does exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file: '/home/masterartem/Studies/UdacitySelfDriving/BehavioralCloning/sample_data/IMG/center_2020_02_16_16_22_49_042.jpg'"
     ]
    }
   ],
   "source": [
    "path_img = '../sample_data/IMG/'\n",
    "path_data = '../sample_data/driving_log.csv'\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio as imgio\n",
    "import numpy as np\n",
    "import cv2\n",
    "import csv\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def read_data(img_path, driving_data): #this part was borrowed from the Udacity's prep video on this lab\n",
    "    lines = []\n",
    "    with open(driving_data) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for line in reader:\n",
    "            lines.append(line)\n",
    "    images = []\n",
    "    measurements = []\n",
    "    firstline = True\n",
    "    for line in lines:\n",
    "        if firstline:\n",
    "            firstline = False\n",
    "            continue\n",
    "        # Append the images for the left, center and right cameras to an input data list. Append measurements to a label list\n",
    "        source_path = line[0]\n",
    "        #source_path_left = line[1]\n",
    "        #source_path_right = line[2]\n",
    "        filename = source_path.split('/')[-1]\n",
    "        #filename_left = source_path_left.split('/')[-1]\n",
    "        #filename_right = source_path_right.split('/')[-1]\n",
    "        current_path = img_path + filename\n",
    "        image = imgio.imread(current_path)\n",
    "        images.append(image)\n",
    "        measurement = float(line[3])\n",
    "        measurements.append(measurement)\n",
    "    return images, measurements\n",
    "\n",
    "def image_manipulation(in_image):\n",
    "    dim = (200, 66)\n",
    "    resized_img = cv2.resize(in_image, dim, interpolation = cv2.INTER_AREA)\n",
    "    image_yuv = cv2.cvtColor(resized_img, cv2.COLOR_RGB2YUV)\n",
    "    #Y_img, U_img, V_img = cv2.split(image_yuv)\n",
    "    #out_image = np.stack([Y_img, U_img, V_img])\n",
    "    return image_yuv\n",
    "\n",
    "\n",
    "plt.imshow(imgio.imread(path_img+'center_2020_02_16_16_22_49_042.jpg'))\n",
    "image = imgio.imread(path_img+'center_2020_02_16_16_22_49_042.jpg')\n",
    "\n",
    "new_image = image_manipulation(image)\n",
    "plt.imshow(new_image)\n",
    "#plt.imshow(new_image[1])\n",
    "#plt.imshow(new_image[2])\n",
    "\n",
    "\n",
    "\n",
    "# Read the data\n",
    "'''images, measurements = read_data(path_img, path_data)        \n",
    "\n",
    "\n",
    "path_img = '/examples/IMG/'\n",
    "path_data = 'examples/driving_log.csv'\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Dense, Flatten\n",
    "import imageio as imgio\n",
    "import numpy as np\n",
    "import cv2\n",
    "import csv\n",
    "\n",
    "\n",
    "def read_data(img_path, driving_data): #this part was borrowed from the Udacity's prep video on this lab\n",
    "    lines = []\n",
    "    with open(driving_data) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for line in reader:\n",
    "            lines.append(line)\n",
    "    images = []\n",
    "    measurements = []\n",
    "    firstline = True\n",
    "    for line in lines:\n",
    "        if firstline:\n",
    "            firstline = False\n",
    "            continue\n",
    "        # Append the images for the left, center and right cameras to an input data list. Append measurements to a label list\n",
    "        source_path = line[0]\n",
    "        #source_path_left = line[1]\n",
    "        #source_path_right = line[2]\n",
    "        filename = source_path.split('/')[-1]\n",
    "        #filename_left = source_path_left.split('/')[-1]\n",
    "        #filename_right = source_path_right.split('/')[-1]\n",
    "        current_path = img_path + filename\n",
    "        image = imgio.imread(current_path)\n",
    "        images.append(image)\n",
    "        measurement = float(line[3])\n",
    "        measurements.append(measurement)\n",
    "    return images, measurements\n",
    "\n",
    "def image_manipulation(in_image):\n",
    "    dim = (200, 66)\n",
    "    resized_img = cv2.resize(in_image, dim, interpolation = cv2.INTER_AREA)\n",
    "    image_yuv = cv2.cvtColor(resized_img, cv2.COLOR_RGB2YUV)\n",
    "    #Y_img, U_img, V_img = cv2.split(image_yuv)\n",
    "    #out_image = np.stack([Y_s, U_i, V_i])\n",
    "    return image_yuv\n",
    "\n",
    "images, measurements = read_data(path_img, path_data)        \n",
    "\n",
    "X_train = np.array(images)\n",
    "y_train = np.array(measurements)\n",
    "\n",
    "## Create a CNN model. We are taking the Nvidia's End-to-End Deep Learning model\n",
    "model = Sequential()\n",
    "# Convert to YUV color scheme\n",
    "model.add(Lambda(lambda x: image_manipulation(x), input_shape=(66,200,3)))\n",
    "# Normalization\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(66,200,3)))\n",
    "# Convolutional layer 1\n",
    "model.add(Conv2D(3, (5,5), stride=2, padding = 'valid'))\n",
    "# Convolutional layer 2\n",
    "model.add(Conv2D(24, (5,5), stride=2, padding = 'valid'))\n",
    "# Convolutional layer 3\n",
    "model.add(Conv2D(36, (5,5), stride=2, padding = 'valid'))\n",
    "# Convolutional layer 4\n",
    "model.add(Conv2D(48, (3,3), padding  = 'valid'))\n",
    "# Convolutional layer 5\n",
    "model.add(Conv2D(64, (3,3), padding = 'valid'))\n",
    "# Convolutional layer 6\n",
    "model.add(Conv2D(64, (3,3), padding = 'valid'))\n",
    "\n",
    "model.add(Flatten())\n",
    "# Dropout layer\n",
    "model.add(Dropout(0.6))\n",
    "# Fully connected layers\n",
    "model.add(Dense(1164))\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=7)\n",
    "model.save('model.h5')\n",
    "'''\n",
    "#model.compile(loss='mse', optimizer='adam')\n",
    "#model.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epochs=7)\n",
    "#model.save('model.h5')\n",
    "#model.add(Lambda(lambda x: cv2.cvtColor(x, cv2.COLOR_BGR2YUV), input_shape=(160,320,3)))\n",
    "#model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
